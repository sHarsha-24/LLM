{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP20G1WNJlmvw4XGzRrgCCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sHarsha-24/LLM--NETWORKING/blob/main/LLM(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzEoLxRf-HXH"
      },
      "outputs": [],
      "source": [
        "sentence = input(\"Enter a sentence: \")\n",
        "\n",
        "\n",
        "words = sentence.split()\n",
        "print(\"Word Tokens:\", words)\n",
        "\n",
        "\n",
        "characters = list(sentence)\n",
        "print(\"Character Tokens:\", characters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch scikit-learn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load pre-trained Sentence Transformer\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "# Example sentences\n",
        "text1 = \"I love machine learning\"\n",
        "text2 = \"I enjoy studying artificial intelligence\"\n",
        "\n",
        "# Generate embeddings\n",
        "emb1 = get_embedding(text1)\n",
        "emb2 = get_embedding(text2)\n",
        "\n",
        "# Cosine similarity\n",
        "similarity = cosine_similarity(emb1, emb2)\n",
        "\n",
        "print(\"Text Similarity Score:\", similarity[0][0])\n"
      ],
      "metadata": {
        "id": "Nns5Q6Z1-PiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install transformers torch scikit-learn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Sample Dataset (replace with CSV if needed)\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"Government launches new education policy\",\n",
        "        \"Aliens landed in India yesterday\",\n",
        "        \"Stock market shows steady growth\",\n",
        "        \"Drinking cow urine cures cancer\",\n",
        "        \"Scientists discover new planet\"\n",
        "    ],\n",
        "    \"label\": [1, 0, 1, 0, 1]  # 1 = Real, 0 = Fake\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "# Dataset class\n",
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=128\n",
        "        )\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"text\"].tolist(),\n",
        "    df[\"label\"].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = FakeNewsDataset(X_train, y_train)\n",
        "test_dataset = FakeNewsDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training loop (1 epoch â€“ demo)\n",
        "model.train()\n",
        "for batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(**batch)\n",
        "    loss = outputs.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Training completed\")\n",
        "\n",
        "# Prediction\n",
        "model.eval()\n",
        "news = [\"NASA confirms water on Mars\"]\n",
        "inputs = tokenizer(news, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    prediction = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "print(\"Prediction:\", \"Real News\" if prediction.item() == 1 else \"Fake News\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iGeyN_Tc-sOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        ")\n",
        "\n",
        "# Sample texts\n",
        "texts = [\n",
        "    \"I love this product, it works perfectly!\",\n",
        "    \"This is the worst experience ever\",\n",
        "    \"The movie was okay, not bad\",\n",
        "    \"I am extremely happy with the service\",\n",
        "    \"I hate waiting in long queues\"\n",
        "]\n",
        "\n",
        "# Analyze sentiment\n",
        "for text in texts:\n",
        "    result = sentiment_analyzer(text)[0]\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Sentiment:\", result[\"label\"])\n",
        "    print(\"Confidence:\", round(result[\"score\"], 3))\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "1NZ05YA7_F9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RztIpt8g_MPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}