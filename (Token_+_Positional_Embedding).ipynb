{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Input sentence\n",
        "# ----------------------------\n",
        "sentence = \"I love machine learning\"\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Tokenization\n",
        "# ----------------------------\n",
        "tokens = sentence.lower().split()\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Vocabulary creation\n",
        "# ----------------------------\n",
        "vocab = {word: idx for idx, word in enumerate(tokens)}\n",
        "vocab_size = len(vocab)\n",
        "print(\"Vocabulary:\", vocab)\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Token Embedding Matrix\n",
        "# ----------------------------\n",
        "embedding_dim = 6  # size of embedding vector\n",
        "np.random.seed(42)\n",
        "\n",
        "embedding_matrix = np.random.rand(vocab_size, embedding_dim)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Lookup Embedding for each token\n",
        "# ----------------------------\n",
        "token_embeddings = np.array([\n",
        "    embedding_matrix[vocab[token]] for token in tokens\n",
        "])\n",
        "\n",
        "print(\"\\nToken Embeddings:\")\n",
        "print(token_embeddings)\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Positional Embedding\n",
        "# ----------------------------\n",
        "max_len = len(tokens)\n",
        "positional_embedding = np.random.rand(max_len, embedding_dim)\n",
        "\n",
        "print(\"\\nPositional Embeddings:\")\n",
        "print(positional_embedding)\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Final Embedding (Token + Position)\n",
        "# ----------------------------\n",
        "final_embeddings = token_embeddings + positional_embedding\n",
        "\n",
        "print(\"\\nFinal Embeddings (Token + Positional):\")\n",
        "print(final_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fb4SVVAzNDE",
        "outputId": "d23cd76f-caf7-4574-c26a-a162c3a8effe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['i', 'love', 'machine', 'learning']\n",
            "Vocabulary: {'i': 0, 'love': 1, 'machine': 2, 'learning': 3}\n",
            "\n",
            "Token Embeddings:\n",
            "[[0.37454012 0.95071431 0.73199394 0.59865848 0.15601864 0.15599452]\n",
            " [0.05808361 0.86617615 0.60111501 0.70807258 0.02058449 0.96990985]\n",
            " [0.83244264 0.21233911 0.18182497 0.18340451 0.30424224 0.52475643]\n",
            " [0.43194502 0.29122914 0.61185289 0.13949386 0.29214465 0.36636184]]\n",
            "\n",
            "Positional Embeddings:\n",
            "[[0.45606998 0.78517596 0.19967378 0.51423444 0.59241457 0.04645041]\n",
            " [0.60754485 0.17052412 0.06505159 0.94888554 0.96563203 0.80839735]\n",
            " [0.30461377 0.09767211 0.68423303 0.44015249 0.12203823 0.49517691]\n",
            " [0.03438852 0.9093204  0.25877998 0.66252228 0.31171108 0.52006802]]\n",
            "\n",
            "Final Embeddings (Token + Positional):\n",
            "[[0.8306101  1.73589027 0.93166772 1.11289292 0.74843321 0.20244493]\n",
            " [0.66562846 1.03670027 0.6661666  1.65695812 0.98621653 1.7783072 ]\n",
            " [1.13705641 0.31001122 0.86605799 0.623557   0.42628048 1.01993334]\n",
            " [0.46633354 1.20054954 0.87063288 0.80201615 0.60385572 0.88642986]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "os_lAvSF1L5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}